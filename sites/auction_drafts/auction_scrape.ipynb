{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import urlparse\n",
    "import pymongo \n",
    "from pymongo import MongoClient\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def get_draft_date(soup):\n",
    "#     draft_deets = soup.find(\"div\", {\"class\": \"games-alert-mod alert-mod2 games-grey-alert\"})\n",
    "#     draft_date = None\n",
    "#     for b in draft_deets.findAll('b'):\n",
    "#         key = b.text.replace(':', '').strip()\n",
    "#         val = b.nextSibling.strip()\n",
    "#         if key=='Draft Date':\n",
    "#             val = b.nextSibling.replace(',','').replace('.','')[4:].strip()\n",
    "#             draft_date = datetime.strptime(val, '%b %d %Y')\n",
    "#     return draft_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_league_draft_picks(soup):\n",
    "   \n",
    "    connection = MongoClient()\n",
    "    db = connection['espn_leagues_drafts']\n",
    "    auction_drafts = db['auction_drafts']\n",
    "    \n",
    "    #draft_date = get_draft_date(soup)\n",
    "    draft = soup.find(\"div\", {\"class\": \"games-fullcol games-fullcol-extramargin\"})\n",
    "    draft_results=draft.find('table')\n",
    "    league_picks = []\n",
    "    for team in draft_results.findAll('table'):\n",
    "        team_name = team.find('a').text\n",
    "        team_link = team.find('a')['href']\n",
    "        parsed=urlparse.urlparse(team_link)\n",
    "        team_id=urlparse.parse_qs(parsed.query)['teamId'][0]\n",
    "        season_id = urlparse.parse_qs(parsed.query)['seasonId'][0]\n",
    "        league_id = urlparse.parse_qs(parsed.query)['leagueId'][0]\n",
    "\n",
    "        #skip the first row because it has team info\n",
    "        for pick_details in team.findAll('tr')[1:]:\n",
    "\n",
    "            for i, pick_detail in enumerate(pick_details.findAll('td')):\n",
    "                if i%3==0:\n",
    "                    nom_order=int(pick_detail.text)\n",
    "                elif (i-1)%3==0:\n",
    "                    player_link = pick_detail.find('a')\n",
    "                    if not player_link == None:\n",
    "                        player_name = player_link.text\n",
    "                        player_id = player_link['playerid']\n",
    "                        #not sure what this is yet....\n",
    "                        unique_team_id = player_link['teamid']\n",
    "                    else:\n",
    "                        player_name = ''\n",
    "                        player_id = -9999999999\n",
    "                        unique_team_id = -9999999999\n",
    "                else:\n",
    "                    price = int(pick_detail.text.replace('$',''))\n",
    "\n",
    "            pick_dict = {\"league_id\":league_id,\n",
    "                         #\"draft_date\":draft_date,\n",
    "                        \"team_name\":team_name,\n",
    "                        \"team_id\":team_id,\n",
    "                        \"unique_team_id\":unique_team_id,\n",
    "                        \"season_id\":season_id,\n",
    "                        \"nom_order\":nom_order,\n",
    "                        \"player_name\":player_name,\n",
    "                        \"player_id\":player_id,\n",
    "                        \"player_name_id\":\"%s (%s)\"%(player_name, player_id),\n",
    "                        \"price\":price}\n",
    "            \n",
    "            auction_drafts.insert_one(pick_dict)\n",
    "            #league_picks.append(pick_dict)\n",
    "            \n",
    "    return league_picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_picks(year):\n",
    "\n",
    "    #all_picks = []\n",
    "    for draft_recap in os.listdir(year):\n",
    "        #print draft_recap\n",
    "        if not draft_recap.startswith(\".\"):\n",
    "            draft_file = open('%s/%s'%(year,draft_recap),'r')\n",
    "            soup = BeautifulSoup(draft_file,\"lxml\")\n",
    "            #print draft_file\n",
    "            get_league_draft_picks(soup)\n",
    "            draft_file.close()\n",
    "            \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# connection = MongoClient()\n",
    "# db = connection['espn_leagues_drafts']\n",
    "# drafts = db['drafts']\n",
    "# drafts.drop()\n",
    "# drafts = db['drafts']\n",
    "# drafts.insert_many()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_all_picks('2015')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
